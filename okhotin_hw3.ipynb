{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#%matplotlib inline\n",
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=990, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.purity_index = 1\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return l_s + r_s - np.sum(l_c**2, axis=1) / l_s - np.sum(r_c**2, axis=1) / r_s\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        l_entropy = np.sum(l_c * np.log(l_c), axis=1) - l_s * np.log(l_s)\n",
    "        r_entropy = np.sum(r_c * np.log(r_c), axis=1) - r_s * np.log(r_s)\n",
    "        return (l_entropy + r_entropy) / 2.0\n",
    "        \n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        l_misclass = 1 - l_c / np.repeat(l_s, l_c.shape[1]).reshape(-1, l_c.shape[1]) \n",
    "        r_misclass = 1 - r_c / np.repeat(r_s, r_c.shape[1]).reshape(-1, r_c.shape[1])\n",
    "        return (l_misclass + r_misclass) / 2.0\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.sqrt(n_feature))]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.log(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return range(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, int(feature_id)] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        x_data, y_data = self.__sort_samples(x, y)\n",
    "        split_y = y_data[self.min_samples_split:-self.min_samples_split]\n",
    "        critical_points_ids = np.where(split_y[1:] != split_y[:-1])[0] + self.min_samples_split + 1\n",
    "        \n",
    "        if len(critical_points_ids) == 0:\n",
    "            return np.inf, None\n",
    "        \n",
    "        points_delta = critical_points_ids - np.append([self.min_samples_split], critical_points_ids[:-1])\n",
    "        mas = np.zeros((critical_points_ids.shape[0], self.num_class))\n",
    "        mas[np.arange(critical_points_ids.shape[0]), y_data[critical_points_ids - 1]] = 1\n",
    "        cls = mas * points_delta.reshape(-1, 1)\n",
    "        cls[0] = cls[0] + np.bincount(y_data[:self.min_samples_split], minlength=self.num_class)\n",
    "        \n",
    "        tmp = np.bincount(y_data)\n",
    "        template = np.hstack((tmp, np.zeros(self.num_class - tmp.shape[0])))  \n",
    "        l_c = np.cumsum(cls, axis=0)  \n",
    "        r_c = template - l_c\n",
    "        l_s = critical_points_ids.reshape(l_c.shape[0])\n",
    "        r_s = y_data.shape[0] - l_s\n",
    "\n",
    "        g = self.G_function(l_c, l_s, r_c, r_s)\n",
    "        id_x = np.argmin(g)\n",
    "    \n",
    "        elem_id = l_s[id_x]\n",
    "        return g[id_x], (x_data[elem_id-1] + x_data[elem_id]) / 2.0\n",
    "            \n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \n",
    "        if ((self.max_depth <= depth) or \\\n",
    "            (self.sufficient_share <= sum((np.unique(y, return_counts=True)[1] / y.shape[0])**2)) or \\\n",
    "            (y.shape[0] < self.min_samples_split)):\n",
    "            \n",
    "            self.tree[node_id] = [self.__class__.LEAF_TYPE, np.argmax(np.bincount(y))]\n",
    "            \n",
    "        else:\n",
    "            features = self.get_feature_ids(x.shape[1])\n",
    "            mas = np.array([self.__find_threshold(x[:, f], y) for f in features])\n",
    "            best_feature = np.argmin(mas[:,0])\n",
    "            best_threshold = mas[best_feature, 1]\n",
    "            \n",
    "            if best_threshold == None:\n",
    "                self.purity_index *= sum((np.unique(y, return_counts=True)[1] / y.shape[0])**2)\n",
    "                self.tree[node_id] = [self.__class__.LEAF_TYPE, np.argmax(np.bincount(y))] \n",
    "            else:\n",
    "                l_x, r_x, l_y, r_y = self.__div_samples(x, y, best_feature, best_threshold)\n",
    "                if (l_x.size == 0) or (r_x.size == 0):\n",
    "                    self.tree[node_id] = [self.__class__.LEAF_TYPE, np.argmax(np.bincount(y))]\n",
    "                else:   \n",
    "                    self.tree[node_id] = [self.__class__.NON_LEAF_TYPE, best_feature, best_threshold]\n",
    "                    self.__fit_node(l_x, l_y, 2*node_id + 1, depth+1)\n",
    "                    self.__fit_node(r_x, r_y, 2*node_id + 2, depth+1)\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).shape[0]\n",
    "        self.dim_X = x.shape[1]\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857142857142858"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857142857142858"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Speed Dating Data.csv', encoding='cp1251') \n",
    "\n",
    "for i in df.columns:\n",
    "    if type(df[i][0]) not in [np.float64, np.int64, float]:\n",
    "        df.drop(i,axis=1, inplace=True)\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].isnull().sum()>500:\n",
    "        df.drop(i,axis=1, inplace=True)\n",
    "\n",
    "df = df.fillna(-10000)\n",
    "df.drop('id', axis=1)\n",
    "y = df.loc[:, 'gender'].values\n",
    "X = df.drop('gender', axis=1).iloc[:,:].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 131 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 934 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9916433389604746"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9671402421526741"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_importances(my_clf):\n",
    "    \n",
    "    def recur_calc_feature_importances(node_id, feature_importances, count): \n",
    "        node = my_clf.tree[node_id]\n",
    "        if node[0] == my_clf.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, _ = node\n",
    "            feature_importances[feature_id] += 1\n",
    "            count += 1\n",
    "            \n",
    "            _, tmp = recur_calc_feature_importances(2 * node_id + 1, feature_importances, 0)\n",
    "            count += tmp\n",
    "            _, tmp = recur_calc_feature_importances(2 * node_id + 2, feature_importances, 0)\n",
    "            count += tmp\n",
    "        \n",
    "        return feature_importances, count\n",
    "    \n",
    "    feature_importances = np.zeros(my_clf.dim_X)\n",
    "    feature_importances, count = recur_calc_feature_importances(0, feature_importances, 0)\n",
    "    feature_importances /= count\n",
    "    \n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_features</th>\n",
       "      <th>names_of_my_features</th>\n",
       "      <th>sklearn_features</th>\n",
       "      <th>names_of_sklearn_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iid</td>\n",
       "      <td>56</td>\n",
       "      <td>exphappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>fun1_1</td>\n",
       "      <td>62</td>\n",
       "      <td>shar1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>partner</td>\n",
       "      <td>15</td>\n",
       "      <td>race_o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>imprace</td>\n",
       "      <td>0</td>\n",
       "      <td>iid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>music</td>\n",
       "      <td>60</td>\n",
       "      <td>fun1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62</td>\n",
       "      <td>shar1_1</td>\n",
       "      <td>9</td>\n",
       "      <td>partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>race_o</td>\n",
       "      <td>66</td>\n",
       "      <td>fun2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43</td>\n",
       "      <td>museums</td>\n",
       "      <td>54</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>wave</td>\n",
       "      <td>53</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56</td>\n",
       "      <td>exphappy</td>\n",
       "      <td>39</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   my_features names_of_my_features  sklearn_features  \\\n",
       "0            0                  iid                56   \n",
       "1           60               fun1_1                62   \n",
       "2            9              partner                15   \n",
       "3           33              imprace                 0   \n",
       "4           53                music                60   \n",
       "5           62              shar1_1                 9   \n",
       "6           15               race_o                66   \n",
       "7           43              museums                54   \n",
       "8            5                 wave                53   \n",
       "9           56             exphappy                39   \n",
       "\n",
       "  names_of_sklearn_features  \n",
       "0                  exphappy  \n",
       "1                   shar1_1  \n",
       "2                    race_o  \n",
       "3                       iid  \n",
       "4                    fun1_1  \n",
       "5                   partner  \n",
       "6                    fun2_1  \n",
       "7                  shopping  \n",
       "8                     music  \n",
       "9                    sports  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({})\n",
    "data['my_features'] = np.argsort(calc_feature_importances(my_clf))[-10:][::-1]\n",
    "data['names_of_my_features'] = df.columns[data['my_features']]\n",
    "data['sklearn_features'] = np.argsort(clf.feature_importances_)[-10:][::-1]\n",
    "data['names_of_sklearn_features'] = df.columns[data['sklearn_features']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "param_dist = {\n",
    "              \"min_samples_split\": range(2, 5),\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"max_features\": range(4, 10)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=20, cv=5)\n",
    "grid_search = GridSearchCV(clf, param_grid=param_dist, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=None,\n",
       "          param_distributions={'min_samples_split': range(2, 5), 'criterion': ['gini', 'entropy'], 'max_features': range(4, 10)},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'min_samples_split': range(2, 5), 'criterion': ['gini', 'entropy'], 'max_features': range(4, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=random_search.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=grid_search.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
